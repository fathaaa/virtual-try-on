{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 d:\\OneDrive\\Bangkit Academy\\Project\\Image Based\\Train\\test1.jpg: 640x512 1 Upper-Body, 199.9ms\n",
      "Speed: 3.0ms preprocess, 199.9ms inference, 234.8ms postprocess per image at shape (1, 3, 640, 512)\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "model = YOLO(r\"D:\\OneDrive\\Bangkit Academy\\Project\\Image Based\\1\\runs\\segment\\train3\\weights\\best.pt\")\n",
    "\n",
    "image_path = \"test1.jpg\" \n",
    "image_cloth_path = \"cloth3.jpg\"\n",
    "results = model.predict(image_path)\n",
    "boxes = results[0].boxes.xyxy.tolist()\n",
    "result = results[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ultralytics.engine.results.Results object with attributes:\n",
      "\n",
      "boxes: ultralytics.engine.results.Boxes object\n",
      "keypoints: None\n",
      "masks: ultralytics.engine.results.Masks object\n",
      "names: {0: 'Upper-Body'}\n",
      "obb: None\n",
      "orig_img: array([[[216, 217, 215],\n",
      "        [216, 217, 215],\n",
      "        [216, 217, 215],\n",
      "        ...,\n",
      "        [212, 212, 212],\n",
      "        [212, 212, 212],\n",
      "        [212, 212, 212]],\n",
      "\n",
      "       [[216, 217, 215],\n",
      "        [216, 217, 215],\n",
      "        [216, 217, 215],\n",
      "        ...,\n",
      "        [212, 212, 212],\n",
      "        [212, 212, 212],\n",
      "        [212, 212, 212]],\n",
      "\n",
      "       [[216, 217, 215],\n",
      "        [216, 217, 215],\n",
      "        [216, 217, 215],\n",
      "        ...,\n",
      "        [212, 212, 212],\n",
      "        [212, 212, 212],\n",
      "        [212, 212, 212]],\n",
      "\n",
      "       ...,\n",
      "\n",
      "       [[217, 219, 219],\n",
      "        [217, 219, 219],\n",
      "        [217, 219, 219],\n",
      "        ...,\n",
      "        [209, 211, 211],\n",
      "        [209, 211, 211],\n",
      "        [209, 211, 211]],\n",
      "\n",
      "       [[217, 219, 219],\n",
      "        [217, 219, 219],\n",
      "        [217, 219, 219],\n",
      "        ...,\n",
      "        [209, 211, 211],\n",
      "        [209, 211, 211],\n",
      "        [209, 211, 211]],\n",
      "\n",
      "       [[217, 219, 219],\n",
      "        [217, 219, 219],\n",
      "        [217, 219, 219],\n",
      "        ...,\n",
      "        [209, 211, 211],\n",
      "        [209, 211, 211],\n",
      "        [209, 211, 211]]], dtype=uint8)\n",
      "orig_shape: (751, 564)\n",
      "path: 'd:\\\\OneDrive\\\\Bangkit Academy\\\\Project\\\\Image Based\\\\Train\\\\test1.jpg'\n",
      "probs: None\n",
      "save_dir: 'runs\\\\segment\\\\predict'\n",
      "speed: {'preprocess': 4.967927932739258, 'inference': 240.48328399658203, 'postprocess': 6.000280380249023}\n"
     ]
    }
   ],
   "source": [
    "print(results[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[147.89598083496094, 238.03826904296875, 434.2268981933594, 553.4103393554688]\n"
     ]
    }
   ],
   "source": [
    "print(boxes[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "431\n",
      "350\n"
     ]
    }
   ],
   "source": [
    "bounding_height = int(boxes[0][3] - boxes[0][1])\n",
    "bounding_width = int(boxes[0][2] - boxes[0][0])\n",
    "\n",
    "print(bounding_height)\n",
    "print(bounding_width)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "masks = result.masks\n",
    "mask1 = masks[0]\n",
    "polygon = mask1.xy[0]\n",
    "mask = mask1.data[0].numpy()\n",
    "mask_img = Image.fromarray(mask,\"I\")\n",
    "mask_img = mask_img.convert('RGB')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[          0           0           0 ...           0           0           0]\n",
      " [          0           0           0 ...           0           0           0]\n",
      " [          0           0           0 ...           0           0           0]\n",
      " ...\n",
      " [          0           0           0 ...           0           0           0]\n",
      " [          0           0           0 ...           0           0           0]\n",
      " [          0           0           0 ...           0           0           0]]\n"
     ]
    }
   ],
   "source": [
    "print(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_18880\\1947126645.py:5: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
      "  resized_mask_img = mask_img.resize((width, height), Image.ANTIALIAS)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "image = Image.open(image_path)\n",
    "\n",
    "# Mendapatkan ukuran citra\n",
    "width, height = image.size\n",
    "resized_mask_img = mask_img.resize((width, height), Image.ANTIALIAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lebar citra: 564 pixels\n",
      "Tinggi citra: 751 pixels\n"
     ]
    }
   ],
   "source": [
    "width, height = resized_mask_img.size\n",
    "resized_mask_img_pixels = resized_mask_img.load()\n",
    "print(\"Lebar citra:\", width, \"pixels\")\n",
    "print(\"Tinggi citra:\", height, \"pixels\")\n",
    "#sudah sesuai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_18880\\279353294.py:16: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
      "  white_part_resized = white_part.resize((right-left,bottom-top), Image.ANTIALIAS)\n"
     ]
    }
   ],
   "source": [
    "white_area = (int(boxes[0][0]), int(boxes[0][1]), int(boxes[0][2]), int(boxes[0][3]))\n",
    "scale_factor = 1.05\n",
    "\n",
    "# Calculate the expansion size\n",
    "expand_width = int(((white_area[2] - white_area[0]) * (scale_factor - 1)) / 2)\n",
    "expand_height = int(((white_area[3] - white_area[1]) * (scale_factor - 1)) / 2)\n",
    "\n",
    "# Adjust the coordinates\n",
    "left = (white_area[0] - expand_width)\n",
    "top = (white_area[1] - expand_height)\n",
    "right =(white_area[2] + expand_width)\n",
    "bottom = (white_area[3] + expand_height)\n",
    "\n",
    "# Crop the adjusted white area\n",
    "white_part = resized_mask_img.crop(box=(white_area[0], white_area[1], white_area[2], white_area[3]))\n",
    "white_part_resized = white_part.resize((right-left,bottom-top), Image.ANTIALIAS)\n",
    "\n",
    "# Create a new blank image that will show changes\n",
    "new_img = Image.new('RGB', resized_mask_img.size, (0, 0, 0))\n",
    "new_img.paste(white_part_resized, (left, top))\n",
    "\n",
    "# Show and save the result\n",
    "new_img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "white_part.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mendapatkan objek pixel dari gambar\n",
    "pixels = new_img.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_value = 128\n",
    "for y in range(height):\n",
    "    for x in range(width):\n",
    "        # Ambil nilai piksel (dalam kasus RGB, ambil salah satu komponen saja karena awalnya adalah grayscale)\n",
    "        r, g, b = pixels[x, y]  # Semua nilai r, g, b sama karena asalnya grayscale\n",
    "        if r < threshold_value:\n",
    "            pixels[x, y] = (0, 0, 0)  # Set pixel to black\n",
    "        else:\n",
    "            pixels[x, y] = (255, 255, 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "image2 = Image.open(image_cloth_path)\n",
    "#pixels_cloth = image2.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASUS\\AppData\\Local\\Temp\\ipykernel_18880\\3427305150.py:2: DeprecationWarning: ANTIALIAS is deprecated and will be removed in Pillow 10 (2023-07-01). Use LANCZOS or Resampling.LANCZOS instead.\n",
      "  cloth_resized= image2.resize((bounding_width + adjust_cloth, bounding_height + adjust_cloth), Image.ANTIALIAS)\n"
     ]
    }
   ],
   "source": [
    "adjust_cloth = 150\n",
    "cloth_resized= image2.resize((bounding_width + adjust_cloth, bounding_height + adjust_cloth), Image.ANTIALIAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_pixels = new_img.load()\n",
    "width_mask, height_mask = new_img.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cloth_resized_pixels = cloth_resized.load()\n",
    "width_cloth,height_cloth = cloth_resized.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(63, 79, 93)\n"
     ]
    }
   ],
   "source": [
    "print(cloth_resized_pixels[100,204])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_x = int(boxes[0][0]) - int(adjust_cloth / 2)\n",
    "end_x = int(boxes[0][2]) + int(adjust_cloth / 2)\n",
    "start_y = int(boxes[0][1]) - int(adjust_cloth / 2)\n",
    "end_y = int(boxes[0][3]) + int(adjust_cloth / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for y in range(start_y, end_y-1):\n",
    "    for x in range(start_x, end_x-1):\n",
    "        current_pixel = mask_pixels[x, y]\n",
    "        if current_pixel == (0, 0, 0):\n",
    "            mask_pixels[x, y] = mask_pixels[x,y]  \n",
    "        else:\n",
    "            mask_pixels[x, y] = cloth_resized_pixels[x-start_x,y-start_y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_masking = new_img.copy()\n",
    "final_masking_pixels = final_masking.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_image_ori = Image.open(image_path)\n",
    "final_image_ori_pixels = final_image_ori.load()\n",
    "\n",
    "for y in range(height):\n",
    "    for x in range(width):\n",
    "        current_pixel_2 = final_masking_pixels[x,y]\n",
    "        if current_pixel_2 == (0,0,0):\n",
    "            final_masking_pixels[x,y] = final_image_ori_pixels[x,y]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_masking.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
